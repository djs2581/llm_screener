#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
technical_signals.py

Fetches daily OHLCV data and computes:
- RSI(14), MACD(12,26,9), strict Slow Stochastic (14,3) where slow %K = SMA( fast %K, 3 ) and slow %D = SMA( slow %K, 3 )
- SMA20/50/200
- ATR(14) and ATR% = 100*ATR/Close
- HV20 (20-day close-to-close historical volatility, annualized, in %)
- 20-day average volume
- Swing S1/R1 from recent pivots (5-bar fractal pivots)
- 6-month (~126 trading days) percentile ranks for ATR% and HV20
- Next earnings date (if available) and DTE (trading days)

Applies regimes, triggers, and decision rules described in the user's spec,
and writes a CSV + Markdown table with a compact summary for each ticker.

Dependencies: pandas, numpy, yfinance, python-dateutil
Install: pip install pandas numpy yfinance python-dateutil
Usage example:
    python technical_signals.py --tickers HOOD AMD TSLA PLTR NVDA ALAB BMNR AEO --dj-file DJ.txt

Author: Auto-generated by GPT-5 Thinking
"""
import argparse
import math
import os
import re
from datetime import datetime, timedelta, timezone, date

import numpy as np
import pandas as pd

# --- Helper: coerce DataFrame to Series by taking first column if needed ---
def _as_series(obj):
    import pandas as pd
    if isinstance(obj, pd.DataFrame):
        # If a DataFrame slips in (e.g., multiple 'close' columns), take first
        return obj.iloc[:, 0]
    return obj


try:
    import yfinance as yf
except Exception as e:
    raise SystemExit("Please install yfinance: pip install yfinance") from e

from dateutil.relativedelta import relativedelta

# ------------------------- Utility helpers -------------------------
def pct(x):
    return f"{x:.2f}%"

def safe_pct(x):
    try:
        return f"{x:.2f}%"
    except Exception:
        return ""

def bdays_between(start_dt: date, end_dt: date):
    if pd.isna(start_dt) or pd.isna(end_dt):
        return np.nan
    # business days (Mon-Fri). Market holidays are not removed, acceptable approximation.
    if isinstance(start_dt, (pd.Timestamp, datetime)):
        start_dt = start_dt.date()
    if isinstance(end_dt, (pd.Timestamp, datetime)):
        end_dt = end_dt.date()
    if end_dt < start_dt:
        return 0
    rng = pd.bdate_range(start_dt, end_dt)
    # exclude start day if same day?
    return max(0, len(rng) - 1)

def percent_rank(trailing: pd.Series, value: float):
    s = trailing.dropna().values
    if len(s) == 0 or pd.isna(value):
        return np.nan
    return float((s < value).sum()) / float(len(s))

def last_valid_index(df: pd.DataFrame):
    return df.index[-1]

def SMA(s: pd.Series, length: int):
    return s.rolling(length, min_periods=length).mean()

def EMA(s: pd.Series, length: int):
    return s.ewm(span=length, adjust=False, min_periods=length).mean()

def RSI(series: pd.Series, length: int = 14):
    delta = series.diff()
    up = np.where(delta > 0, delta, 0.0)
    down = np.where(delta < 0, -delta, 0.0)
    roll_up = pd.Series(up, index=series.index).ewm(alpha=1/length, adjust=False).mean()
    roll_down = pd.Series(down, index=series.index).ewm(alpha=1/length, adjust=False).mean()
    rs = roll_up / roll_down
    rsi = 100 - (100 / (1 + rs))
    return rsi

def MACD(series: pd.Series, fast=12, slow=26, signal=9):
    ema_fast = EMA(series, fast)
    ema_slow = EMA(series, slow)
    macd_line = ema_fast - ema_slow
    signal_line = macd_line.ewm(span=signal, adjust=False).mean()
    hist = macd_line - signal_line
    return macd_line, signal_line, hist

def true_range(df: pd.DataFrame):
    high_low = df['High'] - df['Low']
    high_prev_close = (df['High'] - df['Close'].shift(1)).abs()
    low_prev_close = (df['Low'] - df['Close'].shift(1)).abs()
    tr = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1)
    return tr

def ATR(df: pd.DataFrame, length: int = 14):
    tr = true_range(df)
    atr = tr.ewm(alpha=1/length, adjust=False).mean()
    return atr

def strict_slow_stoch(df: pd.DataFrame, k_period=14, smooth_k=3, d_period=3):
    # Fast %K
    ll = df['Low'].rolling(k_period, min_periods=k_period).min()
    hh = df['High'].rolling(k_period, min_periods=k_period).max()
    fast_k = 100 * (df['Close'] - ll) / (hh - ll)
    # strict slow: smooth K with SMA(smooth_k), then D = SMA(d_period) of slow K
    slow_k = fast_k.rolling(smooth_k, min_periods=smooth_k).mean()
    slow_d = slow_k.rolling(d_period, min_periods=d_period).mean()
    return slow_k, slow_d

def hv_cc_annualized(close: pd.Series, window=20):
    logret = np.log(close / close.shift(1))
    # sample std
    vol = logret.rolling(window, min_periods=window).std()
    ann = vol * np.sqrt(252) * 100.0
    return ann

def detect_cross_up(a: pd.Series, b: pd.Series, lookback=2):
    # True if a crossed above b in last N bars
    diff = a - b
    cross = (diff > 0) & (diff.shift(1) <= 0)
    return bool(cross.tail(lookback).any())

def detect_cross_down(a: pd.Series, b: pd.Series, lookback=2):
    diff = a - b
    cross = (diff < 0) & (diff.shift(1) >= 0)
    return bool(cross.tail(lookback).any())

def pivot_levels(df: pd.DataFrame, left=2, right=2):
    # 5-bar fractal by default (2 left, 2 right)
    highs = df['High'].values
    lows = df['Low'].values
    idx = df.index
    ph = None
    pl = None
    for i in range(len(df)-right-1, left-1, -1):
        window_high = highs[i-left:i+right+1]
        window_low = lows[i-left:i+right+1]
        if highs[i] == window_high.max() and (ph is None):
            ph = (idx[i], highs[i])
        if lows[i] == window_low.min() and (pl is None):
            pl = (idx[i], lows[i])
        if ph is not None and pl is not None:
            break
    return pl[1] if pl else np.nan, ph[1] if ph else np.nan

def load_tickers_from_file(path):
    if not path or not os.path.exists(path):
        return []
    with open(path, "r", encoding="utf-8", errors="ignore") as f:
        txt = f.read()
    # Extract symbols (letters, numbers, dots, dashes), uppercase
    syms = re.findall(r"[A-Za-z][A-Za-z0-9\.\-]{0,9}", txt)
    # Filter obvious words that are not tickers if any (very light filter)
    blacklist = {"DJ", "INDEX", "STOCKS", "LONG", "SHORT"}
    cleaned = [s.upper() for s in syms if s.upper() not in blacklist]
    return list(dict.fromkeys(cleaned))  # dedupe preserve order

def next_earnings_date(ticker: str):
    """Try multiple ways to retrieve next earnings date from yfinance.
       Returns (date_or_nan, source_str)
    """
    try:
        tk = yf.Ticker(ticker)
        # Try the new get_earnings_dates API if available
        try:
            ed = tk.get_earnings_dates(limit=4)
            if isinstance(ed, pd.DataFrame) and not ed.empty:
                # take the next future date if available, else most recent
                now = pd.Timestamp.utcnow().tz_localize("UTC")
                future = ed[ed["Earnings Date"] >= now]
                if not future.empty:
                    dt = pd.to_datetime(future.iloc[0]["Earnings Date"]).date()
                    return dt, "get_earnings_dates"
                else:
                    dt = pd.to_datetime(ed.iloc[0]["Earnings Date"]).date()
                    return dt, "get_earnings_dates(past)"
        except Exception:
            pass
        # Fallback: older .calendar attribute
        try:
            cal = tk.calendar
            if isinstance(cal, pd.DataFrame) and not cal.empty:
                # yfinance calendar index may contain 'Earnings Date'
                # Value may be Timestamp(s)
                if "Earnings Date" in cal.index:
                    vals = cal.loc["Earnings Date"].values
                    # take the first
                    if len(vals) > 0:
                        dt = pd.to_datetime(vals[0]).date()
                        return dt, "calendar"
        except Exception:
            pass
    except Exception:
        pass
    return np.nan, ""

def volatility_regime(atr_pct_p):
    if pd.isna(atr_pct_p):
        return ""
    if atr_pct_p < 0.30:
        return "Quiet"
    if atr_pct_p < 0.70:
        return "Normal"
    if atr_pct_p < 0.90:
        return "Hot"
    return "Extreme"

def trend_regime(close, sma20, sma50, sma200):
    if pd.isna(close) or pd.isna(sma20) or pd.isna(sma50) or pd.isna(sma200):
        return "Range"
    if (close > sma200) and (sma20 > sma50):
        return "Uptrend"
    if (close < sma200) or (sma20 < sma50):
        return "Downtrend"
    return "Range"

# ------------------------- Core processing per ticker -------------------------
def process_ticker(ticker: str, period="2y"):
    # Download daily data
    df = yf.download(ticker, period=period, interval="1d", auto_adjust=False, progress=False)
    if df is None or df.empty:
        return None

    # Ensure columns
    df = df[['Open','High','Low','Close','Adj Close','Volume']].copy()

    # Indicators
    df["SMA20"] = SMA(df["Close"], 20)
    df["SMA50"] = SMA(df["Close"], 50)
    df["SMA200"] = SMA(df["Close"], 200)
    df["RSI14"] = RSI(df["Close"], 14)
    df["MACD"], df["MACDsignal"], df["MACDhist"] = MACD(df["Close"], 12, 26, 9)
    df["%K_slow"], df["%D_slow"] = strict_slow_stoch(df, 14, 3, 3)
    df["ATR14"] = ATR(df, 14)
    df["ATRpct"] = 100.0 * (df["ATR14"] / df["Close"])
    df["HV20"] = hv_cc_annualized(df["Close"], 20)
    df["Vol20"] = df["Volume"].rolling(20, min_periods=1).mean()

    # Swing levels
    S1, R1 = pivot_levels(df, 2, 2)

    # Percentile ranks over ~6 months (126 trading days)
    tail = df.tail(126)
    atrpct_p = percent_rank(tail["ATRpct"], df["ATRpct"].iloc[-1])
    hv20_p = percent_rank(tail["HV20"], df["HV20"].iloc[-1])

    # Regimes
    close = float(df["Close"].iloc[-1])
    open_ = float(df["Open"].iloc[-1])
    prev_close = float(df["Close"].iloc[-2]) if len(df) >= 2 else np.nan
    high_prev = float(df["High"].iloc[-2]) if len(df) >= 2 else np.nan
    low_prev = float(df["Low"].iloc[-2]) if len(df) >= 2 else np.nan
    vol = float(df["Volume"].iloc[-1])
    vol20 = float(df["Vol20"].iloc[-1]) if not pd.isna(df["Vol20"].iloc[-1]) else np.nan
    sma20 = float(df["SMA20"].iloc[-1]) if not pd.isna(df["SMA20"].iloc[-1]) else np.nan
    sma50 = float(df["SMA50"].iloc[-1]) if not pd.isna(df["SMA50"].iloc[-1]) else np.nan
    sma200 = float(df["SMA200"].iloc[-1]) if not pd.isna(df["SMA200"].iloc[-1]) else np.nan
    rsi = float(df["RSI14"].iloc[-1]) if not pd.isna(df["RSI14"].iloc[-1]) else np.nan
    rsi_prev = float(df["RSI14"].iloc[-2]) if len(df) >= 2 and not pd.isna(df["RSI14"].iloc[-2]) else np.nan
    macd_line = df["MACD"]
    macd_sig = df["MACDsignal"]
    kslow = df["%K_slow"]
    dslow = df["%D_slow"]
    atr = float(df["ATR14"].iloc[-1]) if not pd.isna(df["ATR14"].iloc[-1]) else np.nan
    atrpct = float(df["ATRpct"].iloc[-1]) if not pd.isna(df["ATRpct"].iloc[-1]) else np.nan
    hv20 = float(df["HV20"].iloc[-1]) if not pd.isna(df["HV20"].iloc[-1]) else np.nan

    trend = trend_regime(close, sma20, sma50, sma200)
    vol_reg = volatility_regime(atrpct_p)

    # Cross detections (last 2 sessions)
    macd_cross_up = detect_cross_up(macd_line, macd_sig, 2)
    macd_cross_down = detect_cross_down(macd_line, macd_sig, 2)
    stoch_cross_up = detect_cross_up(kslow, dslow, 2)
    stoch_cross_down = detect_cross_down(kslow, dslow, 2)

    # Breakout / gap logic
    breakout_above_R1 = (not pd.isna(R1)) and (close > R1) and (not pd.isna(vol20)) and (vol >= 1.5 * vol20)
    gap_up = (not pd.isna(prev_close)) and (open_ >= 1.02 * prev_close)
    held_above_prev_high = (not pd.isna(high_prev)) and (df['Low'].iloc[-1] >= high_prev)
    gap_up_ok = gap_up and held_above_prev_high and (not pd.isna(vol20)) and (vol >= 1.5 * vol20)

    breakdown_below_S1 = (not pd.isna(S1)) and (close < S1) and (not pd.isna(vol20)) and (vol >= 1.5 * vol20)
    gap_down = (not pd.isna(prev_close)) and (open_ <= 0.98 * prev_close)
    stayed_below_prev_low = (not pd.isna(low_prev)) and (df['High'].iloc[-1] <= low_prev)
    gap_down_ok = gap_down and stayed_below_prev_low and (not pd.isna(vol20)) and (vol >= 1.5 * vol20)

    # Triggers (bullish +1 / bearish -1)
    triggers = []
    score = 0
    # Bullish
    if not pd.isna(rsi) and rsi < 30:
        triggers.append("B1"); score += 1
    if macd_cross_up and ((macd_line.iloc[-1] - macd_sig.iloc[-1]) > 0):  # bias to fresh cross
        # Crossover today or yesterday handled by detect; this ensures it's not stale bearish diff
        triggers.append("B2"); score += 1
    if not (pd.isna(close) or pd.isna(sma50)) and (close > sma50) and (df["Close"].iloc[-2] <= df["SMA50"].iloc[-2] if not pd.isna(df["SMA50"].iloc[-2]) else False):
        triggers.append("B3"); score += 1
    if not (pd.isna(close) or pd.isna(sma200)) and (close > sma200) and (df["Close"].iloc[-2] <= df["SMA200"].iloc[-2] if not pd.isna(df["SMA200"].iloc[-2]) else False):
        triggers.append("B4"); score += 1
    if breakout_above_R1:
        triggers.append("B5"); score += 1
    # Golden Cross within last 10 sessions
    if len(df) >= 11:
        s50 = df["SMA50"]
        s200 = df["SMA200"]
        cross_up_last10 = ((s50 - s200) > 0) & ((s50 - s200).shift(1) <= 0)
        if bool(cross_up_last10.tail(10).any()):
            triggers.append("B6"); score += 1
    if gap_up_ok:
        triggers.append("B7"); score += 1
    # Bearish
    if not pd.isna(rsi) and rsi > 70:
        triggers.append("S1"); score -= 1
    if macd_cross_down and ((macd_line.iloc[-1] - macd_sig.iloc[-1]) < 0):
        triggers.append("S2"); score -= 1
    if not (pd.isna(close) or pd.isna(sma50)) and (close < sma50) and (df["Close"].iloc[-2] >= df["SMA50"].iloc[-2] if not pd.isna(df["SMA50"].iloc[-2]) else False):
        triggers.append("S3"); score -= 1
    if not (pd.isna(close) or pd.isna(sma200)) and (close < sma200) and (df["Close"].iloc[-2] >= df["SMA200"].iloc[-2] if not pd.isna(df["SMA200"].iloc[-2]) else False):
        triggers.append("S4"); score -= 1
    if breakdown_below_S1:
        triggers.append("S5"); score -= 1
    # Death Cross within last 10
    if len(df) >= 11:
        s50 = df["SMA50"]
        s200 = df["SMA200"]
        cross_dn_last10 = ((s50 - s200) < 0) & ((s50 - s200).shift(1) >= 0)
        if bool(cross_dn_last10.tail(10).any()):
            triggers.append("S6"); score -= 1
    if gap_down_ok:
        triggers.append("S7"); score -= 1

    # Core decision
    # Volatility & trend gates
    hv_ok = (not pd.isna(hv20_p)) and (hv20_p <= 0.70)
    atr_ok_buy = (not pd.isna(atrpct_p)) and (0.30 <= atrpct_p <= 0.90)
    # Cross conditions
    cross_up_ok = macd_cross_up or stoch_cross_up
    cross_dn_ok = macd_cross_down or stoch_cross_down
    rsi_buy_ok = (not pd.isna(rsi)) and (50 <= rsi <= 65 or (len(df) >= 2 and df["RSI14"].iloc[-2] < 50 <= rsi))
    base_signal = "HOLD"
    breakout_clause = False

    if trend == "Uptrend" and cross_up_ok and rsi_buy_ok and (close > sma20) and ((atr_ok_buy and hv_ok) or (close > R1 and (not pd.isna(vol20)) and (vol >= 1.5 * vol20))):
        base_signal = "BUY"
        if close > R1 and (not pd.isna(vol20)) and (vol >= 1.5 * vol20):
            breakout_clause = True

    # SELL rule
    rsi_rollover = (not pd.isna(rsi_prev)) and (rsi_prev > 75) and (rsi < rsi_prev)
    sell_vol_ok = ((not pd.isna(atrpct_p)) and atrpct_p >= 0.70) or ((not pd.isna(hv20_p)) and hv20_p >= 0.80)
    if (trend == "Downtrend" or (close < sma50)) and (cross_dn_ok or (not pd.isna(rsi) and (rsi < 40 or rsi_rollover))) and sell_vol_ok:
        base_signal = "SELL"

    # Hard overrides
    if not pd.isna(rsi) and rsi >= 80:
        if breakout_above_R1 and (vol >= 2.0 * vol20 if not pd.isna(vol20) else False):
            pass  # allow BUY via breakout clause
        else:
            base_signal = "SELL"
    if not pd.isna(rsi) and rsi <= 25:
        if trend == "Downtrend" and (close < sma200):
            base_signal = "HOLD"
        else:
            base_signal = "BUY"

    # Trigger usage upgrades/downgrades
    if base_signal == "HOLD":
        if score >= 2 and (trend in ("Uptrend","Range")) and (vol_reg in ("Normal","Hot") or (vol_reg == "Quiet" and trend == "Uptrend")):
            base_signal = "BUY"
        elif score <= -2:
            if not ( (not pd.isna(atrpct_p) and atrpct_p < 0.30) and (not pd.isna(hv20_p) and hv20_p < 0.30) ):
                base_signal = "SELL"

    # Earnings proximity filter
    earn_date, earn_src = next_earnings_date(ticker)
    dte = np.nan
    earn_flag = ""
    size_mult = 1.0
    if not pd.isna(earn_date):
        today = datetime.now(timezone.utc).date()
        if earn_date >= today:
            dte = bdays_between(today, earn_date)
            if dte <= 2 and base_signal == "BUY" and not (breakout_above_R1 and (vol >= 2.0 * vol20 if not pd.isna(vol20) else False)):
                # No new BUY entries within 2 days of earnings (unless strong breakout)
                earn_flag = "Earnings ≤2d"
            elif 3 <= dte <= 5:
                size_mult = 0.5
                earn_flag = "Earnings soon"
        else:
            # post-earnings day rules (cap size)
            pass

    # Position sizing & trade levels
    PortfolioUSD = 50000.0
    RiskPctPerTrade = 1.0
    MaxNotionalPct = 15.0
    risk_dollars = PortfolioUSD * RiskPctPerTrade / 100.0
    max_notional = PortfolioUSD * MaxNotionalPct / 100.0
    entry = close
    breakdown_clause = breakdown_below_S1 or gap_down_ok
    if base_signal == "BUY":
        if breakout_clause and close < (R1 if not pd.isna(R1) else close):
            entry = R1
        stop = entry - 1.8 * atr if not pd.isna(atr) else np.nan
        target = min(R1, entry + 2.5 * atr) if not (pd.isna(R1) or pd.isna(atr)) else (entry + 2.5 * atr if not pd.isna(atr) else np.nan)
    elif base_signal == "SELL":
        if breakdown_clause and close > (S1 if not pd.isna(S1) else close):
            entry = S1
        stop = entry + 1.8 * atr if not pd.isna(atr) else np.nan
        target = max(S1, entry - 2.5 * atr) if not (pd.isna(S1) or pd.isna(atr)) else (entry - 2.5 * atr if not pd.isna(atr) else np.nan)
    else:
        stop = np.nan
        target = np.nan

    # shares @ 1% / $50k
    shares = ""
    gap_note = ""
    if gap_up_ok:
        gap_note = "Gap‑Up ≥2% + no fill"
    elif gap_down_ok:
        gap_note = "Gap‑Down ≤−2% + no fill"

    unusual_vol_note = ""
    if not pd.isna(vol20) and vol >= 1.5 * vol20:
        unusual_vol_note = f"Unusual vol ({vol/vol20:.1f}× 20d)"

    if base_signal == "BUY":
        risk_per_share = 1.8 * atr if not pd.isna(atr) else np.nan
        if not (pd.isna(risk_per_share) or risk_per_share <= 0 or pd.isna(entry) or entry <= 0):
            base_shares = math.floor(min(risk_dollars / risk_per_share, max_notional / entry))
            final_shares = math.floor(base_shares * size_mult)
            if (not pd.isna(earn_date)) and not pd.isna(dte) and dte <= 2 and earn_flag == "Earnings ≤2d":
                # No new BUYs; set size to 0
                final_shares = 0
            shares = str(max(0, final_shares))
        else:
            shares = "0 (Too volatile for risk)"
    elif base_signal == "SELL":
        # If you don't want to short, you can interpret as "Exit/trim"
        shares = ""

    # Assemble result row
    row = {
        "Ticker": ticker,
        "Signal": base_signal,
        "Trigger Score": score,
        "Triggers Fired": ",".join(triggers),
        "Rationale": "; ".join([
            f"{trend} + {vol_reg} vol",
            ("Breakout R1" if breakout_above_R1 else ("Breakdown S1" if breakdown_below_S1 else ""))
        ]).strip("; "),
        "S1/R1": f"{S1:.2f}/{R1:.2f}" if not (pd.isna(S1) or pd.isna(R1)) else (f"{S1:.2f}/—" if not pd.isna(S1) else (f"—/{R1:.2f}" if not pd.isna(R1) else "—/—")),
        "ATR% (pctl)": f"{atrpct:.2f}% (p{int(round((atrpct_p or 0)*100)) if not pd.isna(atrpct_p) else '—'})",
        "HV20% (pctl)": f"{hv20:.2f}% (p{int(round((hv20_p or 0)*100)) if not pd.isna(hv20_p) else '—'})",
        "Volatility regime": vol_reg,
        "Entry": f"{entry:.2f}" if not pd.isna(entry) else "—",
        "Stop": f"{stop:.2f}" if not pd.isna(stop) else "—",
        "Target": f"{target:.2f}" if not pd.isna(target) else "—",
        "Size (sh) @1%/$50k": shares,
        "Gap note": gap_note,
        "Earnings & DTE": (f"{earn_date} ({int(dte)}d)" if (not pd.isna(earn_date) and not pd.isna(dte)) else (f"{earn_date}" if not pd.isna(earn_date) else "—")),
        "Volume/gap notes": "; ".join([x for x in [unusual_vol_note, earn_flag] if x])
    }

    # Additional detailed columns (optional; helpful in CSV)
    row.update({
        "Close": f"{close:.2f}",
        "RSI14": f"{rsi:.2f}" if not pd.isna(rsi) else "—",
        "MACD": f"{macd_line.iloc[-1]:.4f}" if not pd.isna(macd_line.iloc[-1]) else "—",
        "MACDsig": f"{macd_sig.iloc[-1]:.4f}" if not pd.isna(macd_sig.iloc[-1]) else "—",
        "%K_slow": f"{kslow.iloc[-1]:.2f}" if not pd.isna(kslow.iloc[-1]) else "—",
        "%D_slow": f"{dslow.iloc[-1]:.2f}" if not pd.isna(dslow.iloc[-1]) else "—",
        "SMA20": f"{sma20:.2f}" if not pd.isna(sma20) else "—",
        "SMA50": f"{sma50:.2f}" if not pd.isna(sma50) else "—",
        "SMA200": f"{sma200:.2f}" if not pd.isna(sma200) else "—",
        "ATR14": f"{atr:.2f}" if not pd.isna(atr) else "—",
        "ATRpct": f"{atrpct:.2f}" if not pd.isna(atrpct) else "—",
        "HV20": f"{hv20:.2f}" if not pd.isna(hv20) else "—",
        "AvgVol20": f"{vol20:.0f}" if not pd.isna(vol20) else "—",
    })

    return row

# ------------------------- Markdown rendering -------------------------
def df_to_markdown(df: pd.DataFrame) -> str:
    # Limit key columns; reorder for readability
    cols = [
        "Ticker","Signal","Trigger Score","Triggers Fired","Rationale","S1/R1",
        "ATR% (pctl)","HV20% (pctl)","Volatility regime",
        "Entry","Stop","Target","Size (sh) @1%/$50k",
        "Gap note","Earnings & DTE","Volume/gap notes"
    ]
    df2 = df[cols].copy()
    # Build markdown
    md = df2.to_markdown(index=False)
    footer = (
        "\n\n_Sizing assumes $50,000 portfolio, 1.0% risk/trade, 15% max notional; "
        "BUYs paused if earnings ≤2 trading days away (unless breakout on ≥2.0× vol). "
        "Shares use stop ≈ 1.8×ATR._"
    )
    return md + footer

# ------------------------- Main -------------------------
def main():
    parser = argparse.ArgumentParser(description="Compute daily technical signals and regimes for a ticker list.")
    parser.add_argument("--tickers", nargs="*", default=["HOOD","AMD","TSLA","PLTR","NVDA","ALAB","BMNR","AEO"], help="Space-separated tickers")
    parser.add_argument("--dj-file", default=None, help="Optional path to DJ.txt; any symbols found will be added")
    parser.add_argument("--period", default="2y", help="yfinance period (e.g., 1y, 2y)")
    parser.add_argument("--out-prefix", default="technical_signals", help="Output filename prefix (CSV/MD)")
    args = parser.parse_args()

    tickers = [t.upper() for t in args.tickers]
    # Merge tickers from DJ file if present
    dj_extra = load_tickers_from_file(args.dj_file) if args.dj_file else []
    for t in dj_extra:
        if t not in tickers:
            tickers.append(t)

    results = []
    for t in tickers:
        try:
            row = process_ticker(t, period=args.period)
            if row:
                results.append(row)
            else:
                results.append({"Ticker": t, "Signal": "N/A", "Trigger Score": "", "Triggers Fired": "", "Rationale": "No data", "S1/R1":"—/—",
                                "ATR% (pctl)":"", "HV20% (pctl)":"", "Volatility regime":"", "Entry":"", "Stop":"", "Target":"",
                                "Size (sh) @1%/$50k":"", "Gap note":"", "Earnings & DTE":"", "Volume/gap notes":""})
        except Exception as e:
            results.append({"Ticker": t, "Signal": "ERROR", "Trigger Score": "", "Triggers Fired": "", "Rationale": f"{type(e).__name__}: {e}", "S1/R1":"—/—",
                            "ATR% (pctl)":"", "HV20% (pctl)":"", "Volatility regime":"", "Entry":"", "Stop":"", "Target":"",
                            "Size (sh) @1%/$50k":"", "Gap note":"", "Earnings & DTE":"", "Volume/gap notes":""})

    df = pd.DataFrame(results)
    csv_path = f"{args.out_prefix}.csv"
    md_path = f"{args.out_prefix}.md"
    df.to_csv(csv_path, index=False)
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(df_to_markdown(df))

    print(f"Wrote {csv_path} and {md_path}")

if __name__ == "__main__":
    main()

def compute_features(df: pd.DataFrame) -> pd.DataFrame:
    """Compute feature set with robust handling for wide OHLCV (DataFrame) inputs.
    Coerces open/high/low/close/volume to Series if DataFrames are provided.
    """
    # Coerce any wide columns to Series (first column)
    c = _as_series(df["close"]) if "close" in df else None
    v = _as_series(df["volume"]) if "volume" in df else None
    h = _as_series(df["high"]) if "high" in df else None
    l = _as_series(df["low"])  if "low"  in df else None
    if c is None or v is None or h is None or l is None:
        raise ValueError("compute_features expects columns: open, high, low, close, volume")

    out = pd.DataFrame(index=df.index)
    out["close"] = c
    out["volume"] = v

    # Moving averages / momentum
    out["sma20"]  = sma(c, 20)
    out["sma50"]  = sma(c, 50)
    out["sma200"] = sma(c, 200)
    out["rsi14"]  = rsi(c, 14)

    macd_line, macd_sig, macd_hist = macd(c)
    out["macd_line"], out["macd_sig"], out["macd_hist"] = macd_line, macd_sig, macd_hist

    # Stochastic & ATR (guard if any missing)
    try:
        k, d = stoch(h, l, c)
        out["stoch_k"], out["stoch_d"] = k, d
    except Exception:
        out["stoch_k"], out["stoch_d"] = np.nan, np.nan

    try:
        out["atr14"] = atr(h, l, c)
    except Exception:
        out["atr14"] = np.nan

    # Returns and position in range
    out["ret_1m"] = c.pct_change(21)
    out["ret_3m"] = c.pct_change(63)
    out["ret_6m"] = c.pct_change(126)

    # Distance to 200SMA (ensure both are Series)
    out["dist_to_sma200"] = (c - out["sma200"]) / out["sma200"]

    out["adv20"] = v.rolling(20).mean()
    out["six_mo_high"] = c.rolling(126).max()
    out["six_mo_low"]  = c.rolling(126).min()
    out["pos_in_range"] = (c - out["six_mo_low"]) / (out["six_mo_high"] - out["six_mo_low"])
    return out
